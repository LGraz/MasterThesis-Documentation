\chapter{NDVI Correction} \label{sec:corr}

{
    Let's remind ourselves that the data from the S2 satellites is distributed  with an SCL and we therefore have some evidence about what is observed at each pixel for each sampled time (cf. table~\ref{tab:satelite/scl_classes}). So far, we have only considered points, labeled as cloud- and shadow-free (SCL45). However, we remind ourselves of the satellite images in figure~\ref{fig:satelite/time_series_2021_P112/35_scl4_2021-06-03.png}, where we had cloudy images despite the `vegetation' label and see vegetation in figure~\ref{fig:satelite/time_series_2021_P112/40_scl10_2021-06-28.png} even though we are supposed to observe `cirrus clouds'.
    
    % In this chapter, we would like to improve the NDVI interpolation by inspecting also other SCL-classes and by using more than just the two bands used to calculate the NDVI (B4 and B8). 


    % The SCL classification is only on a mixed model based on the S2 bands.
    
    In this chapter, we will try to improve our NDVI interpolation by not relying only on the observed NDVI, but by training our own model to correct the NDVI using all S2 bands. For this, we introduce several statistical modelling approaches and discuss the strengths and weaknesses for each of them. After correcting the observed NDVI, we will assess the uncertainties of our corrections and translate them into weights. These will be used for the subsequent interpolation. This step-by-step procedure is illustrated by the figure~\ref{fig:step_plot_ndvi_corr} in the appendix. Finally, we will evaluate which combination of {{IM}}s and correction model performs the best.
}

\section{Considering other SCL Classes}{\label{sec:corr_otherSCL}
    In figure~\ref{fig:ndvi_corr/residuals_scl_classes} we plot the observed NDVI and notice that some blue points which correspond to the SCL-class 10 (thin cirrus clouds) follow the interpolated line closely. Hence, they might be useful in improving an interpolation fit.

    \begin{my_figure}[ht]{width=0.6\textwidth}{ndvi_corr/residuals_scl_classes}
        \caption[Smoothing splines fit considering SCL45.]{A smoothing splines fit considering green and yellow points (SCL45).}
        \label{fig:ndvi_corr/residuals_scl_classes}
    \end{my_figure}

    To get an impression of whether there is some useful information contained in non-SCL45 observations, we would like to compare the observed NDVI with the true NDVI. But since, we do not have any ground truth data, we will make the following assumption:
    \stepcounter{equation}
    \begin{assumption}{\theequation}%(true NDVI)
        \label{true_ndvi_assumption}
        The ``true'' NDVI value at time $t$ can be successfully estimated by robustified LOOCV interpolation using high-quality observations. That is, the interpolated value  (using a robustified {{IM}} from chapter~\ref{sec:itpl})  considering the points $P^{SCL45}\setminus P_t$. In the following, we will call this estimate the ``true''-NDVI.
    \end{assumption}

    We would like to get an idea if there is any information that can be recovered from non-SCL45 observations. For that, we will check for the other SCL-classes if there is a relation between the ``true'' NDVI (derived with robustified SS) and the observed NDVI. Thus, we pair each ``true'' NDVI with its observed one, collect all pairs, and create a scatter plot for each SCL-class in fig~\ref{fig:ndvi_corr/scl_residuals_scatter}.
    As expected, the ``true'' and the observed NDVI seem to be highly correlated for SCL45. But we can also detect some patterns of correlation in the SCL-classes 2, 3, 7, 8 and 10.  

    \begin{my_figure}[h]{width=1\textwidth}{ndvi_corr/scl_residuals_scatter}
        \caption[``True'' vs. observed NDVI --- for each SCL class]{For each SCL class, we compare the true NDVI with the observed NDVI. (The true NDVI was estimated with LOOCV smoothing splines, and we used all observations of 10\% of the total pixels.)}
        \label{fig:ndvi_corr/scl_residuals_scatter}
    \end{my_figure}

    It might be tempting to just include some of the mentioned SCL classes for  interpolation. But on the one hand, the choice would not be objective and on the other hand, the correlation seems to be weaker than for SCL45. Therefore, in the following section, we will correct the observed NDVI and estimate the uncertainty of each correction. 
}


% \section{Response and Covariates}{
\section{Correction Models}{
        \label{sec:corr_data_table}
        \label{sec:corr_methods}

    For training an NDVI correction model, we require ground-truth data which we will aim to model using informative covariates. Since ground-truth NDVI data is not available, we will again use the assumption~\ref{true_ndvi_assumption} and use the ``true'' NDVI instead. There is no canonical answer to the question of which covariates we should use. It is a tradeoff between simplicity, generalizability, and performance (with the danger of overfitting). 
    Our desire with the NDVI correction is to develop a product that is simple to use and understand. Therefore, in the subsequent, we will only take the spectral data of the satellite (i.e., all the bands) and the observed NDVI derived from it as covariates. We organize the chosen covariates in the design matrix $X$\footnote{Strictly speaking, we include also the intercept and introduce one dummy variable for each SCL-class.}, where each row corresponds to a $P_t$ (i.e., a pixel at a time $t$) and each column to one covariate.    

    In the following, we will introduce different approaches, to model the relationship between the response $y:=\operatorname{NDVI}_\text{``true''}\in \R^n$ and the design matrix $X\in\R^{n \times p}$. First, we will study the basic OLS. Second, we look at the LASSO, a penalized adaptation of the OLS which is known to successfully deal with highly correlated covariates. Afterwards, GAMs are introduced, which model the response similar to OLS but allow for non-linear relations. Last but not least, we discuss RF and MARS, which are both flexible modelling approaches. % since only weak assumptions on the relationship between the response and covariates are made. 

    Note that in order to reduce computation time, only $10\%$ of the data has been used to fit the subsequent models, which are still more than 120'000 observations. 
    
    \input{tex/chapters/misc/ml_models.tex}
}

\section{Weighted Interpolation}{
% \section{Uncertainty Estimation}{
    \label{sec:corr_uncertainty}
    Once we corrected the NDVI using the models described in the previous section, we are left with the problem that not every correction is equally reliable.\footnote{One correction is illustrated in the figure~\ref{fig:step_plot/2017-206_corr.pdf}. In this figure, the outer points (labeled as clouds) have a large scatter.}. Hence, we are interested in a measure of how uncertain an estimate is. 
    We achieve this analogously as we corrected the NDVI, by replacing the response $\operatorname{NDVI}_\text{``true''}$ with the absolute residuals $v := \left|y -\hat y\right|$ and modeling their relationship with the covariates defined by $X$.  In this way, we obtain a model for the absolute residuals $v$ and the estimator $\hat v$. 
    % }
    
% \section{Interpolation}{
    \label{sec:corr_link}
    In the following, we will convert our uncertainty estimate into weights that can be used for interpolation. For this, consider a pixel $P$, $\hat y^{(P)}$ its corrected NDVI values and $\hat v^{(P)}$ the estimated uncertainties of $\hat y^{(P)}$. In order to interpolate $\hat y^{(P)}$, we will give less weight to unreliable observations. Thus, we define the link function connecting $\hat v$ with weights: 
    \begin{equation}
        \label{eq:corr_link}
        w^{(P)}_\tau:=\frac{1}{R} \frac{1}{\hat v^{(P)}_\tau}, 
        \quad \text{ for } \tau=1,\dots, n_P
    \end{equation}  
    where $\tau$ is an index over the satellite images and $R:=\frac{\sum_i^{n_P}\hat v^{(P)}_i}{n_P}$ a normalization constant. The normalization is needed since for some {{IM}}s, inflating the sum of weights would decrease the effect of the smoothing. 
}


\section{Resulting Interpolation Strategies ({{IS}}s)}{
    \label{sec:corr_itpl_stat}
    We have developed the following procedure to obtain a new interpolation (keyword-wise):
    \begin{Nenumerate}
        \item LOOCV Interpolation (+ robustify?) to get ``true'' NDVI
        \item Correction 
        \item Uncertainty estimation
        \item Interpolation (+ robustify?)
    \end{Nenumerate}
    At each step we have a choice, more precisely:
    \begin{Nitemize}
        \item Interpolation: SS / DL
        \item Robustify: Yes / No
        \item Correction \& uncertainty estimation: RF / OLS -- considering only SCL-classes / OLS -- considering all selected covariates / MARS / GAM / LASSO / no correction.
    \end{Nitemize}
    As it is not feasible to try every possible combination, we make the following restrictions on which combinations we will consider:
    \begin{Nitemize}
        \item We use the same {{IM}} each time.
        \item Either we robustify both times, or we do not robustify at all.
        \item We use the same underlying method for correction and uncertainty estimation.
    \end{Nitemize}

    In this fashion, we obtain 28 distinct {{IS}}s, which we will benchmark in the next section.
}

\section{Evaluation via (relative) Yield Prediction Error (relative YPE)}{
    \label{sec:ndvi_corr_eval}
    In this section, we introduce the relative YPE and utilize it to evaluate the 28 {{IS}}s from section~\ref{sec:corr_itpl_stat}. 
    % idea
    The fundamental assumption is that the closer the interpolated NDVI {TS} is to the true one, the better it can be used to determine crop yield. Implicitly, we believe that an NDVI {TS} that better models yield will incorporate more true information about the underlying vegetation. 
    Therefore, we want to determine a comparable YPE for each {{IS}} and choose it as a benchmark criterion. 
    This is an objective measure since we have not considered crop yield in any of our previous steps. Moreover, this criterion is justified by the fact that yield estimation has been a motivation for the interpolation.

    \begin{definition}(Relative YPE) \label{def:YPE}
        Let $y\in \R^n$ be the yield, $M$ be a model for estimating $y$, and $\hat y = M(X)$ where $X$ describes the data\footnote{We will use the matrixes derived in section~\ref{sec:corr_yield_est}.}. 
        We define the relative YPE as the relative RMSE in yield estimation. Formally expressed:
        \begin{equation}
            YPE = \frac{\sqrt{\sum_{i=1}^n(y_i - \hat y_i)}}{\bar y}, %Y bar wird nicht erklärt
        \end{equation}
        where $\bar y$ denotes the sample mean. For the (non-relative) YPE do not divide by $\bar y$.
    \end{definition}

    % \subsubsection*{Yield Estimation}
    {
        \label{sec:corr_yield_est}
        We would like to estimate the yield from the NDVI {TS} produced by all the {{IS}}s for all pixels. However, given the high dimensionality and different lengths of the interpolation (not every {TS} has the same start and end point), we must first map each NDVI {TS} into a low-dimensional vector space of covariates. For this, we will use the following statistics:
        {% covaraites
            \renewcommand{\arraystretch}{1.2} \begin{longtable}{p{0.48\linewidth} p{0.48\linewidth}}
                --- Maximum slope   &   --- Integral\footnoteref{note:integral-min} up to the peak \\
                --- Minimum slope   &   --- Integral\footnoteref{note:integral-min} after peak \\
                --- Integral\footnote{\label{note:integral-min} We will only consider the integral of the function $max(0, NDVI - 0.3)$, where $0.3$ is assumed to be a minimal NDVI value (cf. satellite images~\ref{fig:satelite/time_series_2021_P112/15_scl5_2021-02-23.png} and~\ref{fig:satelite/time_series_2021_P112/45_scl2_2021-07-23.png} with their NDVI in plot~\ref{fig:interpol/ndvi_ts_scl45_grey.pdf}).} over all   &   --- Integral\footnoteref{note:integral-min} from 0-685 GDD \\
                --- Peak (i.e., maximal NDVI)    &   --- Integral\footnoteref{note:integral-min} from 685-1075 GDD     \\
                --- GDD for the Peak &  
            \end{longtable} \renewcommand{\arraystretch}{1}
            % Old itemize
                % \begin{Nitemize}
                %     \item Maximum slope
                %     \item Minimum slope
                %     \item Integral\footnote{\label{note:integral-min} We will only consider the integral of the function $max(0, NDVI - 0.3)$, where $0.3$ is assumed to be a minimal NDVI value. REF} over all
                %     \item Peak (i.e., maximal NDVI)
                %     \item Peak GDD (i.e., value at which the peak is attained)
                %     \item Integral\footnoteref{note:integral-min} up to the peak
                %     \item Integral\footnoteref{note:integral-min} after peak
                %     \item Integral\footnoteref{note:integral-min} from 0-685 GDD
                %     \item Integral\footnoteref{note:integral-min} from 685-1075 GDD    
                % \end{Nitemize}
        }
        For the choice we were inspired by (cf. table 2 in \cite{kamirEstimatingWheatYields2020}). However, we deliberately omit any statistic that involves the minimum (e.g., the NDVI-range), since we regard the minimum as a very error-prone measure due to the large influence of clouds in the {TS}. 
        
        As a result, for each {{IS}}, a matrix is obtained in which each row corresponds to a pixel and both the yield and the covariates (computed by applying the above statistics) are contained.
        Using this matrix, we train a random forest for yield estimation, and compute the integrated OOB\footnote{By the integrated OOB estimates, we denote the predictions for each pixel where only trees are used, where the pixel has not been used (as $n_{tree}$, the number of Trees, grows the fraction of trees which do not contain a certain pixel converges to $\frac{1}{e}$).} estimates $\hat y$. Note that the choice of the modeling approach does not matter much, as long as it is general enough (i.e., able to approximate any function) and we use the same one for each {{IS}}. 
        Finally, for each {{IS}}, we calculate the YPE and describe the results in section~\ref{sec:results_ndvi_corr}.
    }

    
    
    
}



%satelite/time_series_2021_P112/35_scl4_2021-06-03.png 
%satelite/time_series_2021_P112/40_scl10_2021-06-28.png 
%satelite/time_series_2021_P112/30_scl4_2021-05-09.png 
%satelite/time_series_2021_P112/15_scl5_2021-02-23.png 
%satelite/time_series_2021_P112/45_scl2_2021-07-23.png 
%satelite/time_series_2021_P112/33_scl9_2021-05-24.png
