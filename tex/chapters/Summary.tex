\chapter{Conclusion}
\label{s:Conclusion}
\begin{verbatim}
    
- itpl methods, 
    parametric dl 
    non-param 
        discarded 
            kernel methods because of strong bias  
            kriging because assumptions and highdim parameters
            savitzky-golay filter since we will investigate the LOESS which can be thought as its generalization 
            loess slightly best performing itpl method but we notice non-smooth behaviour if data gaps are present
        loess > ss > bspl
        choose ss because of its meaningful definition (minimizing the integral of the second derivative squared (\refeq{eq:ss}))
- robustifying useful?

\end{verbatim}
XXX draw your conclusion to which you came during this thesis



\section{Future Work}{
    \label{ss:FutureWork}

    \subsection{Time Series Correction-Interpolation as a General Method}{
        Throughout this thesis, we developed a correction and interpolation method for the NDVI. However, we never used features of the NDVI. Only the parameter estimated via cross-validation in chapter \ref{sec:itpl_param_est} depends on the scale of the time series. For simplicity, we could thus determine the parameter using Generalized Cross Validation (as \citefullauthor{ripleyFitSmoothingSpline} suggest). Therefore, our approach of interpolation and correction of time series can be applied to arbitrary time series as long as additional information is available. However, further research is required, to demonstrate the usefulness of this approach in general.


        \subsubsection*{Example: Cloud Correction with Uncertainty Estimation and Interpolation}
            This generalization can be used in particular for cloud correction. In the same manner as we corrected the NDVI time series in chapter \ref{sec:corr}, we can correct each spectral band and reunite the corrected bands with the uncertainties. If desired, the time series can also be interpolated before merging as in chapter \ref{sec:corr_link}. The resulting question would be how well this approach performs.
    }



    \subsection{Minor Improvements}
        During this project, we also noticed some minor issues that we would have liked to investigate further if more resources were available. The most relevant of these are:
        \begin{Nitemize}
            \item \textbf{Data:}
            Method how data\todo{which data? I assume the combine harvester point data?} has been extrapolated to the grid could possibly be improved
            \item \textbf{Data:}
            For computational reasons, we mostly considered all years and split the data (on the pixel level) randomly into a train/test set. A leave one year out cross validation might yield more accurate results.
            \item \textbf{Data:}
            We have not included the spectral bands which have a resolution of 60Â m. But precisely these seem to be promising for cloud correction, since they are a proxy of the water (content and form) in the atmosphere.
            % \item \textbf{Interpolation:}
            % Penalized Regressions as described in ... are similar to smoothing splines (c.f. ...) but different. Better?XXX
            \item \textbf{NDVI Correction:}
            Explore the effect of different link functions between the estimated absolute residuals and the weights in section \ref{sec:corr_link}.

            XXX weight/uncertainty function 
            (problem of weight function -> some outer points get really low weights (just because others in the middle have very little residuals and thus very high weight))
            \item \textbf{NDVI Correction:}
            Yield is not the only target variable of interest. Other variables like protein content could also be used in section \ref{sec:ndvi_corr_eval} for the method evaluation. 
        \end{Nitemize}
}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "MasterThesisSfS"
%%% End: 
