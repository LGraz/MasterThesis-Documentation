\chapter{Conclusion}
\label{sec:Conclusion}

% GENERAL INFORMATION    

    In this thesis, we investigated how to model vegetation dynamics through NDVI {TS} derived from satellite images. The major challenges were how to deal with contaminated observations (due to clouds or shadows) and how to interpolate the observed NDVI values. 
    % ITPL METHODS
    A summary of the {{IM}}s considered can be found in the table~\ref{sec:itpl}. 
    
        %% Rejected
    Filtering the observations contaminated by clouds and shadows via SCL introduces data gaps, especially in winter. Therefore, we aim for {{IM}}s that handle such data gaps well. The Nadaraya-Watson kernel estimator struggles when there are no or too few points in the window of interest; Universal Kriging is biased towards the mean, particularly in environments with no data (cf. figure~\ref{fig:kriging_parameters}); \nth{2} order Fourier series can deviate strongly within data gaps (cf. figure~\ref{fig:interpol/fourier_dl_comparison}) and the Savitzky-Golay filter depends on equidistant observations (cf. section~\ref{sec:discussion_itpl_data_gaps}). Occasionally, a generalization of the Savitzky-Golay filter --- the Locally Weighted Regression --- has also shown surprising behavior in data gaps (cf. figure~\ref{fig:interpol/2x3_loess_robust}).
    
        % LOOCV performance
    In contrast, the latter performed well in Leave-One-Out-Cross-Validation (LOOCV) (cf. table~\ref{tab:cv-statistics_itpl-methods}). Nevertheless, we prefer the Smoothing Splines (SS) as they perform only slightly worse there, but produce a much smoother curve (cf. figure~\ref{fig:interpol/2x3_SS_robust} and~\ref{fig:interpol/2x3_loess_robust}). SS flexibly approximate the data while keeping curvature low (cf. equation~\refeq{eq:ss}). B-splines, on the other hand, were worse than SS with respect to every score function tested, and their smoothing mechanism is also less interpretable. However, the best performing method here is the approximation by a Double logistic (DL), which makes strong assumptions about the shape of the NDVI curve. Problems for the parameter estimation of the DL (and the FS) have been resolved by restricting the parameter space by generous but realistic values. Problems with overfitting in universal kriging were overcome by determining the variogram parameters for a subsample of NDVI {TS} and finally using the median of each parameter. 
        %Candiates (SS and DL)
    In the end, we choose DL and SS as our preferred {{IM}}s.
%        \todo[inline]{Question: more details for the justification of the interpolation candidates?} 




% NDVI CORRECTION
The traditional answer to the question of how to deal with contaminated observations is that we only consider observations that are labeled as vegetation or bare soil by the SCL (SCL45). The unreliability of this labeling, however, is illustrated in figure~\ref{fig:witzwil_selected_satellite_images}. Moreover, filtered observations (non-SCL45) might still contain valuable information (see section~\ref{sec:corr_otherSCL}). Therefore, we do not adhere to traditional (SCL) filtration, but instead consider all observations and correct the observed NDVI with uncertainty estimations. For this, we use statistical models that take additional information such as the remaining spectral bands, the current SCL label and the observed NDVI into account. But before we interpolate the corrected NDVI values, we assign a weight to each observation, corresponding to its uncertainty. The uncertainty is estimated analogously as the NDVI has been corrected. That is, taking the same covariates but replacing the old response ($\operatorname{NDVI}^\text{true}$) with a new one ($\operatorname{abs}(\operatorname{NDVI}^\text{corrected}-\operatorname{NDVI}^\text{true})$).
    % Considerd {{IS}}s
    By combining different {{IM}}s with various statistical models, we obtain 28 different Interpolation Strategies ({{IS}}s) (see section~\ref{sec:corr_itpl_stat}). To assess which of these {{IS}}s is best, we assume that the better the {{IS}}, the better it allows interpolated NDVI {TS} to predict yield. Surprisingly, the best strategy is the one with SS and the simplest static model considered, which uses only the observed NDVI and SCL classification.
    % Best Itpl strategy
Let us recapitulate the best {{IS}}: First, we estimate the `true' NDVI (c.f. assumption~\ref{true_ndvi_assumption}) using SS via LOOCV. Then obtain the corrected NDVI using the OLS\textsuperscript{SCL} model (cf. equation~\refeq{eq:corr_lm}). Subsequently, we estimate the absolute error with the OLS\textsuperscript{SCL} model (cf. equation~\refeq{eq:corr_lm}) and thereby obtain weights which are supposed to reflect the reliability of the corrected NDVI (cf. equation~\refeq{eq:corr_link}). Finally, we perform a weighted interpolation with SS.


% robustification
    To make the {{IM}}s more robust to contaminated observations (outliers) that remained after SCL filtration, we generalized an iterative technique. After an initial fit, in each iteration we give less weight to observations with comparatively large residuals and then perform a weighted interpolation (see section~\ref{sec:loess_robustify}). However, after too many iterations, non-contaminated points might get ignored (i.e., given a zero weight). The greatest improvements, on the other hand, were perceived after the first iteration (see figure~\ref{fig:interpol/2x3_SS_robust}). 
    % robustification -- good or bad?
    For evaluating the generalized robustification technique, we used raw LOOCV performance on the one hand, and the ability to model the NDVI TS for crop yield estimation on the other hand.
    On the one hand, robustification (narrowly) misses the target of being part of the best {{IS}}. On the other hand, we see in table~\ref{tab:cv-statistics_itpl-methods} that robustification leads to smaller LOOCV residuals in most cases. That is (except for the Fourier approximation) the QAR\textsuperscript{50} and QAR\textsuperscript{75} are smaller for the robustified ones. Hence, when we expect contaminated observations, we advise to robustify the interpolation. 

% Recommendations
As to the question of which {{IM}} we recommend, we consider two cases. If one only intends to fit a curve to the NDVI TS as precisely as possible, we recommend the robustified DL, since it minimizes the LOOCV residuals in most cases (cf. table~\ref{tab:cv-statistics_itpl-methods}). In the event that one requires an interpolation that contains as much information about the plant as possible, we recommend SS. This recommendation is especially valid if we traditionally consider only SCL45 observations without correcting the proposed NDVI. However, we recommend the abovementioned {{IS}} with NDVI correction, because it reduces the unexplained variance of the NDVI-based yield prediction by 10.5\% (cf. section~\ref{sec:discussion_iplfstrategy-choose}). Considering all the error sources (cf. section~\ref{sec:discuss_high-rmse-in-yield-prdiction}) and the fact that we only consider the NDVI {TS}, we consider the 10.5\% to be a solid improvement.%\footnote{The 10.5\% corresponds to the reduction in variance in the crop yield estimate with the corrective {{IS}} compared to a traditional SS interpolation. 100\% would thus suggest that we could perfectly predict yield from the interpolated NDVI curve (despite all the sources of error mentioned above).}



\section{Future Work}{
    \label{sec:FutureWork}

    \subsection{Time Series Correction-Interpolation as a General Method}{
        Throughout this thesis, we developed a correcting uncertainty-weighted interpolation procedure for the NDVI. However, we never relied on any properties of the NDVI. Only the parameter estimated via cross-validation in chapter~\ref{sec:itpl_param_est} depends on the scale of the {TS}. For simplicity, we could thus determine the parameter using Generalized Cross Validation \citep{ripleyFitSmoothingSpline2022}. Therefore, our approach of interpolation and correction of {TS} can be applied to arbitrary {TS} if additional information is available. This includes TS outside of satellite imagery or remote sensing. However, further research is required, to demonstrate the general usefulness of this approach.

        As an example, we could perform cloud-correction with uncertainty estimation and interpolation.
        In the same manner as we corrected the NDVI {TS} for a pixel in chapter~\ref{sec:corr}, one could look at each spectral band separately and correct it with an uncertainty estimate. Subsequently, one reassembles the corrected bands and translates the multiple estimated uncertainties into one. Optionally, the {TS} can also be interpolated before merging, as in chapter~\ref{sec:corr_link}. The remaining question is how such an approach might perform.
    }



    \subsection{Minor Improvements}
        During this project, we also noticed some minor issues that we would have liked to investigate further if more resources had been available. The most relevant of these are:
        \begin{Nitemize}
            \item \textbf{Data:}
            The method how the combine harvester point cloud has been extrapolated to the 10m grid of S2 could possibly be improved.
            \item \textbf{Data:}
            We have not included the spectral bands that have a resolution of 60 m. But precisely these seem to be promising for cloud correction, since they are a proxy of the water (content and form) in the atmosphere.
            \item \textbf{Data:}
            \cite{raiyaniSentinel2ImageScene2021} present a machine learning approach that supposedly improves the SCL and thus could improve our results that are based on the SCL.
            % \item \textbf{Interpolation:}
            % Penalized Regressions as described in ... are similar to smoothing splines (cf. ...) but different. Better?XXX
            \item \textbf{NDVI Correction:}
            Explore the effect of different link and normalizing functions % between the estimated absolute residuals and the weights 
            in section~\ref{sec:corr_link}. Currently, we run into the danger of some outer points getting nearly ignored because one estimated absolute residual for some interior point is close to zero.
            \item \textbf{NDVI Correction:}
            Yield is not the only target variable of interest. Other variables like protein content could also be used in section~\ref{sec:ndvi_corr_eval} for the method evaluation. 
        \end{Nitemize}
}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "MasterThesisSfS"
%%% End: 
