\chapter{Conclusion}
\label{sec:Conclusion}

% GENERAL INFORMATION    

    In this thesis, we investigated how to model vegetation dynamics through NDVI {TS} derived from satellite images. The Scene Classification Layer (SCL), supplied by the European Space Agency, played a key role in this process. The major challenges faced were how to deal with contaminated observations (due to clouds or shadows) and how to interpolate the observed NDVI values. 
    % ITPL METHODS
    A summary of the interpolation methods considered can be found in the table \ref{sec:itpl}. 
    
        % robustification
    To make the interpolation methods more robust to contaminated observations (outliers) that remained after SCL filtration, we generalized an iterative technique. After an initial fit, in each iteration we give less weight to observations with comparatively large residuals and then perform a weighted interpolation (see section \ref{sec:loess_robustify}). However, after too many iterations, non-contaminated points might get ignored (i.e., given a zero weight). The greatest improvements, on the other hand, were perceived after the first iteration (see figure \ref{fig:interpol/2x3_SS_robust}). 
    % The success of this robustification is assessed later.
    
        %% Rejected
    Filtering the observations contaminated by clouds and shadows via SCL introduces data gaps, especially in winter. Therefore, we aim for interpolation methods that handle such data gaps well. The Nadaraya-Watson kernel estimator struggles when there are no or too few points in the window of interest; Universal Kriging is biased towards the mean, particularly in environments with no data (cf. figure \ref{fig:kriging_parameters}); 2cd order Fourier series can deviate strongly within data gaps (cf. figure \ref{fig:interpol/fourier_dl_comparison}) and the Savitzky-Golay filter depends on equidistant observations (cf. section \ref{sec:discussion_itpl_data_gaps}). Occasionally, a generalization of the Savitzky-Golay filter --- the Locally Weighted Regression --- has also shown surprising behavior in data gaps (cf. figure \ref{fig:interpol/2x3_loess_robust}).
    
        % LOOCV performance
    In contrast, the latter performed well in Leave-One-Out-Cross-Validation (LOOCV) (cf. table \ref{tab:cv-statistics_itpl-methods}). Nevertheless, we prefer the Smoothing Splines (SS) as they perform only slightly worse there, but produce a much smoother curve (cf. figure \ref{fig:interpol/2x3_SS_robust} and \ref{fig:interpol/2x3_loess_robust}). SS flexibly approximate the data while keeping curvature low (cf. equation \refeq{eq:ss}). B-splines, on the other hand, were worse than SS with respect to every score function tested, and their smoothing mechanism is also less interpretable. However, the best performing method here is the approximation by a Double logistic (DL), which makes strong assumptions about the shape of the NDVI curve. Problems for the parameter estimation of the DL (and the Fourier series) have been resolved by restricting the parameter space by generous but realistic values. Problems with overfitting in universal kriging were overcome by determining the variogram parameters for a subsample of NDVI {TS} and finally using the median of each parameter. 
        %Candiates (SS and DL)
    In the end, we choose DL and SS as our preferred interpolation methods.
        \todo[inline]{Question: more details for the justification of the interpolation candidates?} 




% NDVI CORRECTION
The traditional answer to the question of how to deal with contaminated observations is that we only consider observations that are labeled as vegetation or bare soil by the SCL (SCL45). The unreliability of this labeling, however, is illustrated in figure \ref{fig:witzwil_selected_satellite_images}. Moreover, filtered observations (non-SCL45) might still contain valuable information (see section \ref{sec:corr_otherSCL}). Therefore, we do not adhere to traditional (SCL) filtration but instead consider all observations and correct the observed NDVI with uncertainty estimation. For this, we use statistical models that take additional information such as the remaining spectral bands, the current SCL label and the observed NDVI into account. But before we interpolate the corrected NDVI values, we assign a weight to each observation, corresponding to its uncertainty. The uncertainty is estimated analogously as the NDVI has been corrected. 
    % Considerd Interpolation strategies
    By combining different interpolation methods (with and without robustification) with various statistical models, we obtain 28 different interpolation strategies (see section \ref{sec:corr_itpl_stat}). To assess which of these interpolation strategies is best, we assume that the better the interpolation strategy, the better it allows interpolated NDVI {TS} to predict yield. Surprisingly, the best strategy is the one with non-robust SS and the simplest static model considered, which uses only the observed NDVI and SCL classification.
    % Best Itpl strategy
Let us recapitulate the best interpolation strategy: First, we estimate the ``true'' NDVI (REF) using SS via LOOCV. Then obtain the corrected NDVI using the OLS-SCL model (cf. equation \refeq{eq:corr_lm}). Subsequently, we estimate the absolute error with the OLS-SCL model (cf. equation \refeq{eq:corr_lm}) and thereby obtain weights which are supposed to reflect the reliability of the corrected NDVI (cf. equation \refeq{eq:corr_link}). Finally, we perform a weighted interpolation with SS.

% robustification -- good or bad?
For evaluating the generalized robustification technique, we used raw LOOCV performance on the one hand, and the ability to model plant growth for crop yield estimation on the other hand.
While the robustification is not part of the best interpolation strategy, it narrowly misses this target. In contrast, we see in table \ref{tab:cv-statistics_itpl-methods} that robustification leads to smaller LOOCV residuals in most cases. That is (with the exception of the Fourier approximation) the 50\% and 75\% quantiles of the absolute residuals are smaller for the robustified ones. Hence, when we expect contaminated observations, we advise to robustify the interpolation. 

% Recommendations
As to the question which interpolation method we recommend, we consider two cases. If one only intends to fit a curve to the data as precisely as possible, we recommend the robustified DL, since it minimizes the LOOCV residuals in most cases (cf. table \ref{tab:cv-statistics_itpl-methods}). In the event that one requires an interpolation that contains as much information about the plant as possible, we recommend the SS. This recommendation is especially valid if we traditionally consider only SCL45 observations without correcting the proposed NDVI. However, we recommend the abovementioned interpolation strategy with NDVI correction, because otherwise over 5\% of the information about the vegetation will be lost from the NDVI {TS} (cf. section \ref{sec:discussion_iplfstrategy-choose}). In light of all the sources of error (cf. section \ref{sec:discuss_high-rmse-in-yield-prdiction}) and the fact that we only consider the NDVI {TS}, we consider the 5\% to be a solid improvement.\footnote{The 5\% corresponds to the reduction in variance in the crop yield estimate with the corrective interpolation strategy compared to a traditional SS interpolation. 100\% would thus suggest that we could perfectly predict yield from the interpolated NDVI curve (despite all the sources of error mentioned above).}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  G E R M A N
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ITPL METHODS
% Für eine zusammenfassung der betrachteten interpolationsmethoden verweisen wir auf die Tabelle \ref{sec:itpl}. 

%     % robustification
%     Um die Interpolationsmethoden robuster gegen contaminierte beobachtungen (Ausreißer) zu machen, welche selbst nach der SCL Filtration verbleiben, haben wir eine iterative Technik verallgemeinert. Dafür geben wir nach einem Initialen Fit den Beobachtungen mit vergleichsweise grossen residuen in der nächsten iteration weniger gewicht und führen anschliessend eine gewichtete Interpolation durch(siehe sektion \ref{sec:loess_robustify}). Bei zu vielen iterationen besteht jedoch die gefahr, dass gute Punkte mit null gewichtet werden. Die größte verbesserung nehmen wir hingegen nach der ersten iteration wahr (siehe Abbildung \ref{fig:interpol/2x3_SS_robust}). 
%         % Den Erfolg dieser Robustifizierung bewerten wir später.

%     %% Rejected
%     Das Filtern via SCL von durch Wolken und Schatten contaminierte Beobachtungen führt dazu, dass wir besonders im Winter Datenlücken haben. Daher ist wichtig für unsere gewählten interpolationsmethode, dass sie gut mit solchen Datenlücken umgehen können. Der Nadaraya-Watson kernel schätzer hat probleme wenn im betrachteten Fenster keine oder zu wenig punkte vorhanden sind; das Universal Kriging tendiert in umgebungen mit keinen daten besonders stark zum mittelwert (vgl. figure \ref{fig:kriging_parameters}); die 2cd order Fourier Series kann stark ausschlagen bei datenpunkten (vgl. figure \ref{fig:interpol/fourier_dl_comparison}) und Savitzky-Golay Filter setzt equidistante beobachtungen vorraus (vgl. sektion \ref{sec:discussion_itpl_data_gaps}). Vereinzelt hat auch eine Generalisierung des Savitzky-Golay Filters -- die Locally Weighted Regression --- überraschendes verhalten in datenlücken aufgezeigt (vgl. figure \ref{fig:interpol/2x3_loess_robust}).
%         % kompakter:
%             % Durch die Filtration von fehlerhaften Beobachtungen, erhalten wir besonders im Winter Datenlücken. Daher ist es ein Kriterium für unsere gewählten interpolationsmethode, dass sie gut mit solchen Datenlücken umgehen können. Der Nadaraya-Watson kernel schätzer, Universal Kriging, 2cd order Fourier Series und Savitzky-Golay Filter konnten hier nicht überzeugen (vgl. sektion \ref{sec:discussion_itpl_data_gaps}). Vereinzelt hat hier auch eine Generalisierung des Savitzky-Golay Filters -- der LOESS --- überraschendes verhalten aufgezeigt.  
%     % LOOCV performance
%     Dieser konnte hingegen bei der Leave-One-Out-Cross-Validation (LOOCV)  überzeugen (cf. table  \ref{tab:cv-statistics_itpl-methods}), jedoch bevorzugen wir die Smoothing Splines (SS), da sie dort nur wenig schlechter abscheiden, aber eine deutlich glattere kurve produzieren (vgl. Abbildung \ref{fig:interpol/2x3_SS_robust} und \ref{fig:interpol/2x3_loess_robust}). Die SS approximieren flexibel die Daten, halten aber gleichzeitig die Krümmung gering (cf. equation \refeq{eq:ss}). B-Splines hingegen waren hinsichtlich jeder getesteten Score Funktion schlechter als SS und ihr smoothing Mechanismus ist auch schlechter Interpretierbar. Am besten schneiden hier jedoch die Approximation durch eine Double logistic (DL) ab, welche starke annahmen über die Form der NDVI kurve macht. Probleme für die Parameterschätzung des DL (und der Fourierreihe) haben wir behoben, indem wir den parameterraum durch großzügige aber realistische werte beschränkt haben. Probleme mit overfitting beim Universal Kriging haben wir behoben, indem wir die variogram-parameter für ein subsample an NDVI zeitreihen bestimmt haben und schlussendlich den median jeweiliger parameter benutzt haben. 
%     %Candiates (SS and DL)
%     Schlussendlich wählen wir DL und SS als unsere Favoriten der Interpolationsmethoden.
%     \todo[inline]{Frage: mehr details für die begründung der Interpolations-kandidaten?} 

%     % NDVI CORRECTION
%     Auf die Frage, wie wir mit den kontaminierten Beobachtungen umgehen sollen, lautet die traditionelle Antwort, dass wir nur Beobachtungen beachten, welche durch die SCL als Vegetation oder als bare soil gelabelt sind (SCL45). In figure \ref{fig:witzwil_selected_satellite_images} wird jedoch die Unzuverlässigkeit dieses Labelings illustriert. Zudem haben wir die festgestellt, dass auch nicht-SCL45 Beobachtungen wertvolle Informationen enthalten können (vgl. Sektion \ref{sec:corr_otherSCL}). Daher halten wir nicht an der traditionellen (SCL-)Filtration sondern betrachten statdessen alle Beobachtungen und korrigieren den beobachten NDVI. Dafür benutzen wir statistische Modelle, die zusätzliche Informationen wie die verbleibenden Spektralbänder in Betracht nehmen. Bevor wir aber die korrigierten NDVI Werte interpolieren, weisen wir jeder Beobachtung ein Gewicht zu, korrespondieren zu ihrer Unsicherheit. Die Unsicherheit wird analog wie die NDVI Korrektur geschätzt. 
%     % Considerd Interpolation strategies
%     Durch die Wahl verschiedener Interpolationsmethoden (mit und ohne robustifizierung) und statistischer Modelle, erhalten wir somit 28 verschiedene Interpolationsstrategien (vgl. Sektion \ref{sec:corr_itpl_stat}). Um zu beurteilen, welche dieser Interpolationsstragie am besten ist, machen wir die folgende Annahme: ``je besser die Interpolationsstrategie, desto besser kann damit interpolierte NDVI Zeitreihe den Ertrag voraussagen''. Überraschender Weise ist die beste Strategie, die mit nicht-robustifizierten SS und dem einfachsten betrachteten statischen Modell, welches nur den beobachteten NDVI und die SCL Klassifizierung benutzt.
%     % Best Itpl strategy
%     Let us recapitulate the best interpolation strategy: First, we estimate the ``true'' NDVI using SS via LOOCV, then obtain the corrected NDVI using the OLS-SCL model (cf. equation \refeq{eq:corr_lm}). Subsequently, we estimate the absolute error with the OLS-SCL model (cf. equation \refeq{eq:corr_lm}) and thereby obtain weights which are supposed to reflect the reliability of the corrected NDVI (cf. equation \refeq{eq:corr_link}). Finally, we perform a weighted interpolation with SS.

%% robustification -- good or bad?
% Nun bewerten wir die verallgemeinerte Robustifizierung technik einerseits mit der rohen LOOCV performance, andererseits mit der Fähigkeit das Planzenwachstum für die Ernteertragsschätzung zu modellieren.
% Zwar ist die die robustifizierung nicht teil der besten Interpolationsstragie, verfehlt dieses Ziel aber nur knapp. Hingegen sehen wir in tabelle \ref{tab:cv-statistics_itpl-methods}, dass die robustifizierung in den meisten Fällen zu kleineren LOOCV Residuen führt. Das Heißt mit Ausnahme der Fourier Approximation sind die 50\% und 75\% quantile der absoluten resiuden für die robustifizierten besser. Daher empfehlen wir die robustifizierung durchzuführen, wenn wir mit kontaminierten beobachtungen rechnen. 

%% Recommendations
% Auf die Frage welche interpolationsmethode wir schlussendlich empfehlen, wollen wir zwei Fälle betrachten. Wenn es nur darum geht möglichst präzise eine Kurve den daten anzupassen, empfehlen wir die robustifizierten DL, da diese die LOOCV residuals in den meisten fällen minimieren (vgl. tabelle \ref{tab:cv-statistics_itpl-methods}). Falls wir eine interpolation erhalten wollen die möglichst viele informationen über die pflanze enthält empfehlen wir die SS. Diese empfehlung gilt besonders, falls wir traditionell nur SCL45 beobachtungen betrachten wollen ohne die vorgeschlagene NDVI zu korrigieren. Jedoch empfehlen wir die oben aufgeführte interpolationsstrategie mit NDVI korrektur, da uns ansonsten über 5\% der informationen aus der NDVI zeitreihe abhanden kommmen (vgl. sektion \ref{sec:discussion_iplfstrategy-choose}). Im anbetracht aller Fehlerquellen (cf. section \ref{sec:discuss_high-rmse-in-yield-prdiction}) und der tatsache dass wir nur die NDVI Zeitreihe betrachten wir die 5\% als eine solide verbesserung.\footnote{Die 5\% entsprechen der reduktion der Varianz in der Ernteertragsschätzung mit der korrigierenden Interpolationsstrategie im vergleich zu einer traditonellen SS interpolation. 100\% würden somit andeuten, dass wir an der NDVI kurve perfekt den Ertrag vorraussagen könne (trotz aller genannten Fehlerquellen).}

% \todo[inline]{Anzahl von Beobachtungen, empfehlungen? -- schwierig, weil regelmäßigkeit in `wichtigen' zeiträumen (der veränderung) wichtiger ist.}

\section{Future Work}{
    \label{sec:FutureWork}

    \subsection{Time Series Correction-Interpolation as a General Method}{
        Throughout this thesis, we developed a correction and interpolation method for the NDVI. However, we never used features of the NDVI. Only the parameter estimated via cross-validation in chapter \ref{sec:itpl_param_est} depends on the scale of the {TS}. For simplicity, we could thus determine the parameter using Generalized Cross Validation (as \citefullauthor{ripleyFitSmoothingSpline} suggest). Therefore, our approach of interpolation and correction of {TS} can be applied to arbitrary {TS} as long as additional information is available. However, further research is required, to demonstrate the general usefulness of this approach.


        \subsubsection*{Example: Cloud Correction with Uncertainty Estimation and Interpolation}
            This generalization can be used in particular for cloud correction. In the same manner as we corrected the NDVI {TS} in chapter \ref{sec:corr}, we can correct each spectral band and reunite the corrected bands with the uncertainties. If desired, the {TS} can also be interpolated before merging as in chapter \ref{sec:corr_link}. The resulting question would be how well this approach performs.
    }



    \subsection{Minor Improvements}
        During this project, we also noticed some minor issues that we would have liked to investigate further if more resources were available. The most relevant of these are:
        \begin{Nitemize}
            \item \textbf{Data:}
            Method how combine harvester point data has been extrapolated to the grid could possibly be improved.
            \item \textbf{Data:}
            For computational reasons, we mostly considered all years and split the data (on the pixel level) randomly into a train/test set. A leave one year out cross validation might yield more accurate results.
            \item \textbf{Data:}
            We have not included the spectral bands that have a resolution of 60 m. But precisely these seem to be promising for cloud correction, since they are a proxy of the water (content and form) in the atmosphere.
            \item \textbf{Data:}
            \cite{raiyaniSentinel2ImageScene2021} presents an Machine Learing approach that supposedly improves the SCL and thus could improve our results that are based on the SCL.
            % \item \textbf{Interpolation:}
            % Penalized Regressions as described in ... are similar to smoothing splines (cf. ...) but different. Better?XXX
            \item \textbf{NDVI Correction:}
            Explore the effect of different link and normalizing functions % between the estimated absolute residuals and the weights 
            in section \ref{sec:corr_link}. Currently we run into the danger of some outer points getting nearly ignored just because one estimated absolute residual for some interior point is close to zero.
            \item \textbf{NDVI Correction:}
            Yield is not the only target variable of interest. Other variables like protein content could also be used in section \ref{sec:ndvi_corr_eval} for the method evaluation. 
        \end{Nitemize}
}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "MasterThesisSfS"
%%% End: 
